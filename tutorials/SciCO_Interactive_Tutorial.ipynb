{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üî¨ SciCO - The Zotero Library RAG System\n",
    "\n",
    "Welcome to **SciCO** (Scientific Co-worker)! This interactive tutorial will guide you through:\n",
    "\n",
    "1. **Configuration** - Setting up your environment\n",
    "2. **Zotero Integration** - Connecting to your library and retrieving metadata\n",
    "3. **PDF Processing** - Converting PDFs to searchable markdown\n",
    "4. **Text Chunking** - Breaking documents into semantic pieces\n",
    "5. **Vector Storage** - Creating embeddings for semantic search\n",
    "6. **Retrieval** - Querying your knowledge base\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What is RAG?\n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** combines:\n",
    "- **Vector databases** for semantic search\n",
    "- **Your documents** as the knowledge source\n",
    "- **LLMs** for intelligent question answering\n",
    "\n",
    "This allows you to ask questions about your scientific papers and get answers grounded in your actual sources!"
   ],
   "id": "f316f524255b5f4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## üìã Prerequisites\n",
    "\n",
    "Before starting, ensure you have:\n",
    "\n",
    "‚úÖ **Ollama** installed and running ([https://ollama.ai](https://ollama.ai))  \n",
    "‚úÖ **Zotero** with a populated library  \n",
    "‚úÖ A `.env` file with required variables (see below)  \n",
    "‚úÖ Python packages installed (`pip install -r requirements.txt`)\n"
   ],
   "id": "prerequisite_section"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 1Ô∏è‚É£ Configuration\n",
    "\n",
    "The project requires a `.env` file in your project root with these variables:"
   ],
   "id": "1c4ed18c0ba44d58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üìù Required Environment Variables"
   ],
   "id": "b7a41fcea696661e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:42.901822Z",
     "start_time": "2025-10-22T14:40:42.898941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example .env file structure:\n",
    "# Copy this to your .env file and fill in the paths\n",
    "\n",
    "example_env = \"\"\"\n",
    "# Name of the collection in your Zotero library\n",
    "COLLECTION_NAME='Your Collection Name'\n",
    "\n",
    "# Path where markdown files will be saved\n",
    "MARKDOWN_FOLDER_PATH='/path/to/markdown/output'\n",
    "\n",
    "# Path to your Zotero data folder (contains zotero.sqlite)\n",
    "ZOTERO_LIBRARY_PATH='/path/to/Zotero/data'\n",
    "\n",
    "# Path to the ChromaDB index file (should end in .db)\n",
    "INDEX_PATH='/path/to/index/chroma.db'\n",
    "\n",
    "# (Optional) For testing\n",
    "TEST_PDF_PATH='/path/to/test/paper.pdf'\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìÑ Example .env configuration:\")\n",
    "print(example_env)"
   ],
   "id": "e05060f57367368e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Example .env configuration:\n",
      "\n",
      "# Name of the collection in your Zotero library\n",
      "COLLECTION_NAME='Your Collection Name'\n",
      "\n",
      "# Path where markdown files will be saved\n",
      "MARKDOWN_FOLDER_PATH='/path/to/markdown/output'\n",
      "\n",
      "# Path to your Zotero data folder (contains zotero.sqlite)\n",
      "ZOTERO_LIBRARY_PATH='/path/to/Zotero/data'\n",
      "\n",
      "# Path to the ChromaDB index file (should end in .db)\n",
      "INDEX_PATH='/path/to/index/chroma.db'\n",
      "\n",
      "# (Optional) For testing\n",
      "TEST_PDF_PATH='/path/to/test/paper.pdf'\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîß Import Dependencies and Setup"
   ],
   "id": "import_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:42.963071Z",
     "start_time": "2025-10-22T14:40:42.929672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project source to path\n",
    "project_src = Path.cwd()\n",
    "if str(project_src) not in sys.path:\n",
    "    sys.path.insert(0, str(project_src))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Dependencies imported successfully!\")"
   ],
   "id": "bb457cc55e456102",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dependencies imported successfully!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üè• Health Check: Verify Ollama is Running"
   ],
   "id": "health_check_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:42.990056Z",
     "start_time": "2025-10-22T14:40:42.981176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ensure_ollama_running(host: str = \"127.0.0.1\", port: int = 11434, timeout: float = 2.0) -> dict:\n",
    "    \"\"\"Check if Ollama is running and return status info.\"\"\"\n",
    "    base_url = f\"http://{host}:{port}\"\n",
    "    try:\n",
    "        resp = requests.get(f\"{base_url}/api/version\", timeout=timeout)\n",
    "        if resp.status_code == 200:\n",
    "            version_info = resp.json()\n",
    "            return {\n",
    "                'status': 'running',\n",
    "                'url': base_url,\n",
    "                'version': version_info.get('version', 'unknown')\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'message': f\"Ollama responded with status {resp.status_code}\"\n",
    "            }\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\n",
    "            'status': 'not_running',\n",
    "            'message': f\"Cannot reach Ollama at {base_url}\",\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# Run health check\n",
    "ollama_status = ensure_ollama_running()\n",
    "\n",
    "if ollama_status['status'] == 'running':\n",
    "    display(HTML(\n",
    "        f\"<div style='padding:10px; background-color:#1a4d2e; border-left:4px solid #28a745; border-radius:4px; color:#ffffff;'>\"\n",
    "        f\"<strong>‚úÖ Ollama is running!</strong><br>\"\n",
    "        f\"üîó URL: {ollama_status['url']}<br>\"\n",
    "        f\"üì¶ Version: {ollama_status['version']}\"\n",
    "        f\"</div>\"))\n",
    "else:\n",
    "    display(HTML(\n",
    "        f\"<div style='padding:10px; background-color:#5c1a1a; border-left:4px solid #dc3545; border-radius:4px; color:#ffffff;'>\"\n",
    "        f\"<strong>‚ùå Ollama is NOT running!</strong><br>\"\n",
    "        f\"‚ö†Ô∏è {ollama_status.get('message', 'Unknown error')}<br>\"\n",
    "        f\"<em>Please start Ollama before continuing.</em>\"\n",
    "        f\"</div>\"))\n",
    "    raise RuntimeError(\"Ollama must be running to use this notebook.\")\n"
   ],
   "id": "1b5da5ba20bbbb07",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div style='padding:10px; background-color:#1a4d2e; border-left:4px solid #28a745; border-radius:4px; color:#ffffff;'><strong>‚úÖ Ollama is running!</strong><br>üîó URL: http://127.0.0.1:11434<br>üì¶ Version: 0.12.5</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üìä Verify Configuration"
   ],
   "id": "verify_config_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:43.038102Z",
     "start_time": "2025-10-22T14:40:43.035168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if all required environment variables are set\n",
    "required_vars = ['COLLECTION_NAME', 'MARKDOWN_FOLDER_PATH', 'ZOTERO_LIBRARY_PATH', 'INDEX_PATH']\n",
    "config_status = {}\n",
    "\n",
    "print(\"üîç Configuration Status:\\n\")\n",
    "for var in required_vars:\n",
    "    value = os.getenv(var)\n",
    "    config_status[var] = value\n",
    "    status = \"‚úÖ\" if value else \"‚ùå\"\n",
    "    print(f\"{status} {var}: {value if value else 'NOT SET'}\")\n",
    "\n",
    "all_set = all(config_status.values())\n",
    "if all_set:\n",
    "    print(\"\\n‚úÖ All required variables are configured!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Some variables are missing. Please update your .env file.\")"
   ],
   "id": "verify_config_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Configuration Status:\n",
      "\n",
      "‚úÖ COLLECTION_NAME: scico-test\n",
      "‚úÖ MARKDOWN_FOLDER_PATH: example/markdown-library\n",
      "‚úÖ ZOTERO_LIBRARY_PATH: /home/soenke/Zotero\n",
      "‚úÖ INDEX_PATH: example/zotero-vector-storage.db\n",
      "\n",
      "‚úÖ All required variables are configured!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 2Ô∏è‚É£ Zotero Integration\n",
    "\n",
    "Let's connect to your Zotero database and explore what's inside!"
   ],
   "id": "7cdf4e67339e51a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:43.330136Z",
     "start_time": "2025-10-22T14:40:43.084632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from legacy.ZoteroIntegration import ZoteroMetadataRetriever\n",
    "\n",
    "# Initialize the Zotero connection\n",
    "zotero_path = Path(os.getenv('ZOTERO_LIBRARY_PATH'))\n",
    "retriever = ZoteroMetadataRetriever(zotero_path)\n",
    "\n",
    "print(\"üîå Connecting to Zotero database...\")\n",
    "retriever.initialize()\n",
    "print(\"‚úÖ Connected successfully!\")\n",
    "print(f\"üìÇ Database path: {retriever.config.sqlite_path}\")"
   ],
   "id": "zotero_connect_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå Connecting to Zotero database...\n",
      "‚úÖ Connected successfully!\n",
      "üìÇ Database path: /home/soenke/Zotero/zotero.sqlite\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üìö Explore Collections and PDFs"
   ],
   "id": "explore_collections_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:43.414710Z",
     "start_time": "2025-10-22T14:40:43.336225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get PDFs from the configured collection\n",
    "collection_name = os.getenv('COLLECTION_NAME')\n",
    "print(f\"üìñ Retrieving PDFs from collection: '{collection_name}'\\n\")\n",
    "\n",
    "pdfs = retriever.get_pdfs_in_collection(collection_name)\n",
    "\n",
    "if pdfs:\n",
    "    print(f\"‚úÖ Found {len(pdfs)} PDF(s) in this collection\\n\")\n",
    "    print(\"üìÑ First 3 PDFs:\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, pdf in enumerate(pdfs[:3], 1):\n",
    "        print(f\"\\n{i}. {pdf['pdf_name']}\")\n",
    "        print(f\"   Citation Key: {pdf['citationkey'] or 'None'}\")\n",
    "        print(f\"   Item ID: {pdf['itemID']}\")\n",
    "        print(f\"   Path: {pdf['pdf_path'] or 'Not found in storage'}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è No PDFs found in collection '{collection_name}'\")\n",
    "    print(\"Tip: Make sure your collection name matches exactly (case-sensitive)\")"
   ],
   "id": "get_pdfs_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Retrieving PDFs from collection: 'scico-test'\n",
      "\n",
      "‚úÖ Found 1 PDF(s) in this collection\n",
      "\n",
      "üìÑ First 3 PDFs:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1. Wegner et al. - 2023 - Complexity measures for EEG microstate sequences - concepts and algorithms.pdf\n",
      "   Citation Key: wegnerComplexityMeasuresEEG2023\n",
      "   Item ID: 289\n",
      "   Path: /home/soenke/Zotero/storage/9N8E7TQU/Wegner et al. - 2023 - Complexity measures for EEG microstate sequences - concepts and algorithms.pdf\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîç Deep Dive: Get Full Metadata for a PDF"
   ],
   "id": "metadata_deep_dive_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:43.440986Z",
     "start_time": "2025-10-22T14:40:43.421323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's examine the full metadata for the first PDF (if available)\n",
    "def metadata_parser_for_chunks(metadata):\n",
    "    return {\n",
    "        'title': metadata.get('title', 'N/A'),\n",
    "        'authors': metadata.get('authors', 'N/A'),\n",
    "        'year': metadata.get('year', 'N/A'),\n",
    "        'doi': metadata.get('doi', 'N/A'),\n",
    "        'url': metadata.get('url', 'N/A'),\n",
    "        'citation_key': metadata.get('citation_key', 'N/A'),\n",
    "        'collections' : '; '.join([col['name'] for col in metadata.get('collections', [])] if metadata.get('collections') else 'N/A'),\n",
    "        'content_type': 'pdf-zotero',\n",
    "    }\n",
    "\n",
    "if pdfs and pdfs[0]['pdf_path']:\n",
    "    sample_pdf_path = Path(pdfs[0]['pdf_path'])\n",
    "    print(f\"üî¨ Analyzing: {sample_pdf_path.name}\\n\")\n",
    "    \n",
    "    metadata = retriever.get_metadata_for_pdf(sample_pdf_path)\n",
    "    \n",
    "    if metadata:\n",
    "        zotero_metadata = metadata_parser_for_chunks(metadata)\n",
    "        print(\"üìä Full Metadata:\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\nüìñ Title: {metadata.get('title', 'N/A')}\")\n",
    "        print(f\"\\n‚úçÔ∏è Authors: {metadata.get('authors', 'N/A')}\")\n",
    "        print(f\"\\nüìÖ Year: {metadata.get('year', 'N/A')}\")\n",
    "        print(f\"\\nüîó DOI: {metadata.get('doi', 'N/A')}\")\n",
    "        print(f\"\\nüåê URL: {metadata.get('url', 'N/A')}\")\n",
    "        print(f\"\\nüì∞ Publication: {metadata.get('publication_title', 'N/A')}\")\n",
    "        \n",
    "        if metadata.get('abstract'):\n",
    "            abstract = metadata['abstract']\n",
    "            print(f\"\\nüìù Abstract: {abstract[:200]}...\" if len(abstract) > 200 else f\"\\nüìù Abstract: {abstract}\")\n",
    "        \n",
    "        if metadata.get('tags'):\n",
    "            print(f\"\\nüè∑Ô∏è Tags: {', '.join(metadata['tags'])}\")\n",
    "        \n",
    "        if metadata.get('collections'):\n",
    "            print(f\"\\nüìÅ Collections:\")\n",
    "            for coll in metadata['collections']:\n",
    "                print(f\"   - {coll['name']}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Could not retrieve metadata\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid PDF path found for analysis\")\n",
    "    print(\"Tip: Make sure PDFs exist in your Zotero storage folder\")"
   ],
   "id": "metadata_details_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Analyzing: Wegner et al. - 2023 - Complexity measures for EEG microstate sequences - concepts and algorithms.pdf\n",
      "\n",
      "üìä Full Metadata:\n",
      "================================================================================\n",
      "\n",
      "üìñ Title: Complexity measures for EEG microstate sequences - concepts and algorithms\n",
      "\n",
      "‚úçÔ∏è Authors: Wegner, Frederic von; Wiemers, Milena; Hermann, Gesine; T√∂dt, Inken; Tagliazucchi, Enzo; Laufs, Helmut\n",
      "\n",
      "üìÖ Year: 2023\n",
      "\n",
      "üîó DOI: 10.21203/rs.3.rs-2878411/v1\n",
      "\n",
      "üåê URL: https://www.researchsquare.com/article/rs-2878411/v1\n",
      "\n",
      "üì∞ Publication: None\n",
      "\n",
      "üìù Abstract: EEG microstate sequence analysis quantifies properties of ongoing brain electrical activity which is known to exhibit complex dynamics across many time scales. In this report we review recent developm...\n",
      "\n",
      "üìÅ Collections:\n",
      "   - PCI-From-Resting-State-Reconstruction\n",
      "   - scico-test\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 3Ô∏è‚É£ PDF to Markdown Conversion\n",
    "\n",
    "Now let's convert a PDF to structured Markdown using the `marker` library with Ollama."
   ],
   "id": "pdf_conversion_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:49.273859Z",
     "start_time": "2025-10-22T14:40:43.478180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.Tools.PdfToMarkdown import convert_pdf_to_markdown\n",
    "\n",
    "# We'll use the first PDF from our collection (if available)\n",
    "if pdfs and pdfs[0]['pdf_path']:\n",
    "    pdf_path = pdfs[0]['pdf_path']\n",
    "    output_folder = os.getenv('MARKDOWN_FOLDER_PATH')\n",
    "    \n",
    "    print(f\"üìÑ Converting PDF: {Path(pdf_path).name}\")\n",
    "    print(f\"üìÇ Output folder: {output_folder}\")\n",
    "    print(\"\\n‚è≥ This may take a few minutes depending on PDF size...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # Find the generated markdown file\n",
    "        pdf_name = Path(pdf_path).stem\n",
    "        markdown_path = Path(output_folder) / pdf_name / f\"{pdf_name}.md\"\n",
    "\n",
    "        # Convert PDF to markdown\n",
    "        try:\n",
    "            convert_pdf_to_markdown(pdf_path=pdf_path, output_path=output_folder)\n",
    "        except FileExistsError as e:\n",
    "            print('File is already processed')\n",
    "\n",
    "        if markdown_path.exists():\n",
    "            print(f\"\\n‚úÖ Conversion successful!\")\n",
    "            print(f\"üìù Markdown file: {markdown_path}\")\n",
    "            \n",
    "            # Show a preview\n",
    "            with open(markdown_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                preview_length = 500\n",
    "                print(f\"\\nüìñ Preview (first {preview_length} characters):\")\n",
    "                print(\"=\" * 80)\n",
    "                print(content[:preview_length])\n",
    "                print(\"...\")\n",
    "                print(\"=\" * 80)\n",
    "                print(f\"\\nüìä Total characters: {len(content):,}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Markdown file not found after conversion\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during conversion: {e}\")\n",
    "        print(\"Tip: Make sure Ollama is running and the PDF is accessible\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No PDF available for conversion\")\n",
    "    print(\"Skipping this step...\")\n",
    "    markdown_path = None"
   ],
   "id": "pdf_conversion_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Converting PDF: Wegner et al. - 2023 - Complexity measures for EEG microstate sequences - concepts and algorithms.pdf\n",
      "üìÇ Output folder: example/markdown-library\n",
      "\n",
      "‚è≥ This may take a few minutes depending on PDF size...\n",
      "\n",
      "File is already processed\n",
      "\n",
      "‚úÖ Conversion successful!\n",
      "üìù Markdown file: example/markdown-library/Wegner et al. - 2023 - Complexity measures for EEG microstate sequences - concepts and algorithms/Wegner et al. - 2023 - Complexity measures for EEG microstate sequences - concepts and algorithms.md\n",
      "\n",
      "üìñ Preview (first 500 characters):\n",
      "================================================================================\n",
      "![](_page_0_Picture_0.jpeg)\n",
      "\n",
      "# Complexity measures for EEG microstate sequences - concepts and algorithms\n",
      "\n",
      "Frederic von Wegner ( [f.vonwegner@unsw.edu.au \\)](mailto:f.vonwegner@unsw.edu.au) UNSW Sydney Milena Wiemers Klinikum L√ºneburg Gesine Hermann Kiel University Inken T√∂dt Kiel University Enzo Tagliazucchi University of Buenos Aires Helmut Laufs Kiel University\n",
      "\n",
      "Research Article\n",
      "\n",
      "Keywords:\n",
      "\n",
      "Posted Date: May 10th, 2023\n",
      "\n",
      "DOI: <https://doi.org/10.21203/rs.3.rs-2878411/v1>\n",
      "\n",
      "License: This work is \n",
      "...\n",
      "================================================================================\n",
      "\n",
      "üìä Total characters: 96,317\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 4Ô∏è‚É£ Markdown Chunking\n",
    "\n",
    "Large documents need to be split into smaller chunks for effective embedding and retrieval."
   ],
   "id": "chunking_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:53.088977Z",
     "start_time": "2025-10-22T14:40:49.330168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.Tools.TextSplitter import MarkdownChunker\n",
    "\n",
    "# Use the markdown file we just created (or provide a path to an existing one)\n",
    "if 'markdown_path' in locals() and markdown_path and markdown_path.exists():\n",
    "    print(f\"‚úÇÔ∏è Chunking markdown file: {markdown_path.name}\")\n",
    "\n",
    "    # Initialize chunker\n",
    "    chunker = MarkdownChunker(\n",
    "        md_path=str(markdown_path),\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    \n",
    "    # Perform chunking\n",
    "    chunks = chunker.chunk(method='markdown+semantic')\n",
    "\n",
    "    # Add zotero metadata to each chunk\n",
    "    chunks = chunker.add_additional_metadata(metadata=zotero_metadata, splits=chunks)\n",
    "    \n",
    "    print(f\"‚úÖ Created {len(chunks)} chunks\\n\")\n",
    "    \n",
    "    # Show statistics\n",
    "    chunk_lengths = [c.metadata['length'] for c in chunks]\n",
    "    print(\"üìä Chunk Statistics:\")\n",
    "    print(f\"   Min length: {min(chunk_lengths)} chars\")\n",
    "    print(f\"   Max length: {max(chunk_lengths)} chars\")\n",
    "    print(f\"   Avg length: {sum(chunk_lengths) / len(chunk_lengths):.0f} chars\")\n",
    "    \n",
    "    # Display first chunk as example\n",
    "    print(\"\\nüìÑ Example Chunk:\")\n",
    "    print(\"=\" * 80)\n",
    "    example_chunk = chunks[0]\n",
    "    print(f\"ID: {example_chunk.metadata['split_id']}\")\n",
    "    print(f\"\\nMetadata:\")\n",
    "    for key, value in example_chunk.metadata.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "    print(f\"\\nContent:\\n{example_chunk.page_content}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No markdown file available for chunking\")\n",
    "    print(\"Skipping this step...\")\n",
    "    chunks = None"
   ],
   "id": "chunking_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è Chunking markdown file: Wegner et al. - 2023 - Complexity measures for EEG microstate sequences - concepts and algorithms.md\n",
      "‚úÖ Created 230 chunks\n",
      "\n",
      "üìä Chunk Statistics:\n",
      "   Min length: 1 chars\n",
      "   Max length: 5562 chars\n",
      "   Avg length: 409 chars\n",
      "\n",
      "üìÑ Example Chunk:\n",
      "================================================================================\n",
      "ID: 0\n",
      "\n",
      "Metadata:\n",
      "   table: False\n",
      "   split_id: 0\n",
      "   length: 27\n",
      "   title: Complexity measures for EEG microstate sequences - concepts and algorithms\n",
      "   authors: Wegner, Frederic von; Wiemers, Milena; Hermann, Gesine; T√∂dt, Inken; Tagliazucchi, Enzo; Laufs, Helmut\n",
      "   year: 2023\n",
      "   doi: 10.21203/rs.3.rs-2878411/v1\n",
      "   url: https://www.researchsquare.com/article/rs-2878411/v1\n",
      "   citation_key: wegnerComplexityMeasuresEEG2023\n",
      "   collections: PCI-From-Resting-State-Reconstruction; scico-test\n",
      "   content_type: pdf-zotero\n",
      "\n",
      "Content:\n",
      "![](_page_0_Picture_0.jpeg)\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 5Ô∏è‚É£ Vector Storage with ChromaDB\n",
    "\n",
    "Now we'll create embeddings and store them in a vector database for semantic search."
   ],
   "id": "vector_storage_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:53.484742Z",
     "start_time": "2025-10-22T14:40:53.140942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.Tools.VectorStorage import ChromaStorage\n",
    "\n",
    "# Initialize ChromaDB storage\n",
    "index_path = os.getenv('INDEX_PATH')\n",
    "collection_name = os.getenv('COLLECTION_NAME')\n",
    "\n",
    "print(f\"üóÑÔ∏è Initializing vector storage...\")\n",
    "print(f\"üìÇ Index path: {index_path}\")\n",
    "print(f\"üìö Collection: {collection_name}\\n\")\n",
    "\n",
    "storage = ChromaStorage(index_path=index_path, collection_name=collection_name)\n",
    "\n",
    "print(f\"‚úÖ ChromaDB initialized!\")\n",
    "print(f\"üìä Current collection size: {storage.collection.count()} documents\")"
   ],
   "id": "vector_init_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÑÔ∏è Initializing vector storage...\n",
      "üìÇ Index path: example/zotero-vector-storage.db\n",
      "üìö Collection: scico-test\n",
      "\n",
      "‚úÖ ChromaDB initialized!\n",
      "üìä Current collection size: 0 documents\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üì• Add Chunks to Vector Database"
   ],
   "id": "add_chunks_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:54.557994Z",
     "start_time": "2025-10-22T14:40:53.495280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add chunks to the vector database (if we have them)\n",
    "if 'chunks' in locals() and chunks:\n",
    "    print(f\"üì§ Adding {len(chunks)} chunks to vector database...\")\n",
    "    print(\"‚è≥ Creating embeddings (this may take a moment)...\\n\")\n",
    "    \n",
    "    try:\n",
    "        storage.add_documents(chunks)\n",
    "        print(f\"‚úÖ Successfully added chunks!\")\n",
    "        print(f\"üìä Collection now contains: {storage.collection.count()} documents\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error adding chunks: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No chunks available to add\")\n",
    "    print(\"You can still query existing documents if the database is not empty\")"
   ],
   "id": "add_chunks_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Adding 230 chunks to vector database...\n",
      "‚è≥ Creating embeddings (this may take a moment)...\n",
      "\n",
      "‚úÖ Successfully added chunks!\n",
      "üìä Collection now contains: 230 documents\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 6Ô∏è‚É£ Semantic Search & Retrieval\n",
    "\n",
    "Now comes the magic! Let's query our knowledge base."
   ],
   "id": "retrieval_section"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîç Simple Query Example"
   ],
   "id": "simple_query_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:54.638049Z",
     "start_time": "2025-10-22T14:40:54.608525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a query\n",
    "query = \"What is Lemepl Ziv complexity?\"\n",
    "n_results = 5\n",
    "\n",
    "print(f\"üîç Query: '{query}'\")\n",
    "print(f\"üìä Retrieving top {n_results} results...\\n\")\n",
    "\n",
    "try:\n",
    "    results = storage.query(query_texts=[query], n_results=n_results)\n",
    "    \n",
    "    if results['documents'] and results['documents'][0]:\n",
    "        print(f\"‚úÖ Found {len(results['documents'][0])} relevant chunks\\n\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for i, (doc, metadata, distance) in enumerate(zip(\n",
    "            results['documents'][0],\n",
    "            results['metadatas'][0],\n",
    "            results['distances'][0]\n",
    "        ), 1):\n",
    "            # Calculate similarity score (inverse of distance)\n",
    "            similarity = 1 / (1 + distance)\n",
    "            \n",
    "            print(f\"\\nüìÑ Result {i}\")\n",
    "            print(f\"   Similarity: {similarity:.3f} (distance: {distance:.3f})\")\n",
    "            print(f\"   Source: {metadata.get('citation_key', 'Unknown')}\")\n",
    "            print(f\"   Section: {metadata.get('level1', 'N/A')}\")\n",
    "            if metadata.get('level2'):\n",
    "                print(f\"   Subsection: {metadata.get('level2')}\")\n",
    "            print(f\"\\n   Content:\\n   {doc}\")\n",
    "            print(\"\\n\" + \"-\" * 80)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No results found. The database might be empty.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during query: {e}\")"
   ],
   "id": "simple_query_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: 'What is Lemepl Ziv complexity?'\n",
      "üìä Retrieving top 5 results...\n",
      "\n",
      "‚úÖ Found 5 relevant chunks\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìÑ Result 1\n",
      "   Similarity: 0.640 (distance: 0.563)\n",
      "   Source: wegnerComplexityMeasuresEEG2023\n",
      "   Section: $\\begin{array}{c} 362\\\\ 363 \\end{array} \\quad \\text{Lempel-Ziv complexity (LZC)} \\end{array}$\n",
      "\n",
      "   Content:\n",
      "   Fig. 4 Potts model Lempel-Ziv complexity (LZC) for Q = 4 (A) and Q = 5 (B). The same shape is observed for both models.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 2\n",
      "   Similarity: 0.624 (distance: 0.602)\n",
      "   Source: wegnerComplexityMeasuresEEG2023\n",
      "   Section: Complexity measures for EEG microstate sequences - concepts and algorithms\n",
      "\n",
      "   Content:\n",
      "   ., is reproduced by a very short instruction such as 'print A, n times'. As will be explained further below, there are more practical approaches to measure Kolmogorov complexity than trying to find the actual program, namely entropy rate and Lempel-Ziv complexity.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 3\n",
      "   Similarity: 0.624 (distance: 0.603)\n",
      "   Source: wegnerComplexityMeasuresEEG2023\n",
      "   Section: Complexity measures for EEG microstate sequences - concepts and algorithms\n",
      "\n",
      "   Content:\n",
      "   087 088 089 090 091 092 One concept is known as algorithmic or Kolmogorov complexity [\\(Alekseev and](#page-23-3) [Yakobson,](#page-23-3) [1981\\)](#page-23-3) and initially defined complexity as the length of the shortest program that is able to reproduce the input data. This measure increases monotonically with the amount of 'randomness' in the data.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 4\n",
      "   Similarity: 0.616 (distance: 0.624)\n",
      "   Source: wegnerComplexityMeasuresEEG2023\n",
      "   Section: 916 Microstate sequence complexity in wake and sleep\n",
      "\n",
      "   Content:\n",
      "   <span id=\"page-22-0\"></span>1009 1010 1011 1012 Ab¬¥asolo D, da Silva R, Simons S, et al (2014) Lempel-Ziv complexity analysis of local field potentials in different vigilance states with different coarse-graining techniques. In: Romero R (ed) IFMBE Proceedings, XIII Mediterranean Conference on Medical\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Result 5\n",
      "   Similarity: 0.615 (distance: 0.626)\n",
      "   Source: wegnerComplexityMeasuresEEG2023\n",
      "   Section: Complexity measures for EEG microstate sequences - concepts and algorithms\n",
      "\n",
      "   Content:\n",
      "   127 128 129 130 131 132 133 134 135 136 The two complexity concepts discussed can be quantified by a range of metrics that require some disambiguation of the historical terminology. Kolmogorov complexity can be estimated as the randomness of a signal after all correlations have been taken into account (irreducible randomness [\\(Prokopenko et al,](#page-26-2) [2008\\)](#page-26-2)). This is captured by the entropy rate, which is derived from joint entropy (or block entropy) estimates of signal subsequences of different lengths, or via Lempel-Ziv complexity which measures this type of complexity by compressing the signal on the basis of repeated patterns [\\(Lempel and Ziv,](#page-25-3) [1976\\)](#page-25-3).\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üéØ Interactive Query Tool"
   ],
   "id": "interactive_query_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:54.672076Z",
     "start_time": "2025-10-22T14:40:54.666336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search_knowledge_base(query: str, n_results: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Interactive search function with formatted output.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"üîç SEARCH QUERY: {query}\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    try:\n",
    "        results = storage.query(query_texts=[query], n_results=n_results)\n",
    "        \n",
    "        if not results['documents'] or not results['documents'][0]:\n",
    "            print(\"‚ùå No results found.\")\n",
    "            return\n",
    "        \n",
    "        for i, (doc, metadata, distance) in enumerate(zip(\n",
    "            results['documents'][0],\n",
    "            results['metadatas'][0],\n",
    "            results['distances'][0]\n",
    "        ), 1):\n",
    "            similarity_score = 1 / (1 + distance)\n",
    "            \n",
    "            # Create a visual similarity bar\n",
    "            bar_length = int(similarity_score * 20)\n",
    "            bar = \"‚ñà\" * bar_length + \"‚ñë\" * (20 - bar_length)\n",
    "            \n",
    "            print(f\"\\n{'‚ñº' * 40}\")\n",
    "            print(f\"RESULT #{i}\")\n",
    "            print(f\"Relevance: {bar} {similarity_score*100:.1f}%\")\n",
    "            print(f\"\\nüìÅ Source: {metadata.get('title', 'Unknown')}\")\n",
    "            print(f\"      Key: {metadata.get('citation_key', 'Unknown')}\")\n",
    "            print(f\"üìñ Section: {metadata.get('level1', 'N/A')}\")\n",
    "            if metadata.get('level2'):\n",
    "                print(f\"üìë Subsection: {metadata.get('level2')}\")\n",
    "            \n",
    "            print(f\"\\nüí° Content:\")\n",
    "            print(f\"{'‚îÄ' * 80}\")\n",
    "            # Highlight query terms (simple version)\n",
    "            print(doc)\n",
    "            print(f\"{'‚îÄ' * 80}\")\n",
    "        \n",
    "        print(f\"\\n{'=' * 80}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# Example queries to try\n",
    "example_queries = [\n",
    "    \"What is criticality?\",\n",
    "    \"How is consciousness measured during anesthesia?\",\n",
    "    \"What are the main findings of the study?\",\n",
    "    \"What methods were used in the research?\"\n",
    "]\n",
    "\n",
    "print(\"üìù Example queries you can try:\")\n",
    "for i, q in enumerate(example_queries, 1):\n",
    "    print(f\"   {i}. {q}\")\n",
    "\n",
    "print(\"\\nüí° Try running: search_knowledge_base('your question here')\")"
   ],
   "id": "interactive_tool_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Example queries you can try:\n",
      "   1. What is criticality?\n",
      "   2. How is consciousness measured during anesthesia?\n",
      "   3. What are the main findings of the study?\n",
      "   4. What methods were used in the research?\n",
      "\n",
      "üí° Try running: search_knowledge_base('your question here')\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:54.749594Z",
     "start_time": "2025-10-22T14:40:54.724626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Try your first search!\n",
    "search_knowledge_base(\"What is criticality?\", n_results=3)"
   ],
   "id": "first_search_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîç SEARCH QUERY: What is criticality?\n",
      "================================================================================\n",
      "\n",
      "\n",
      "‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº\n",
      "RESULT #1\n",
      "Relevance: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 56.7%\n",
      "\n",
      "üìÅ Source: Complexity measures for EEG microstate sequences - concepts and algorithms\n",
      "      Key: wegnerComplexityMeasuresEEG2023\n",
      "üìñ Section: $\\begin{array}{c} 362\\\\ 363 \\end{array} \\quad \\text{Lempel-Ziv complexity (LZC)} \\end{array}$\n",
      "\n",
      "üí° Content:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "437 438 439 440 441 Excess entropy peaks at the critical point and decays to lower, but non-zero values, away from the critical temperature (T < T<sup>c</sup> and T > Tc). Although asymmetric around the critical temperature, the shape of the excess entropy curve reflects the concept of statistical complexity whereas entropy rate reflects the Kolmogorov complexity concept.\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº\n",
      "RESULT #2\n",
      "Relevance: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 56.6%\n",
      "\n",
      "üìÅ Source: Complexity measures for EEG microstate sequences - concepts and algorithms\n",
      "      Key: wegnerComplexityMeasuresEEG2023\n",
      "üìñ Section: Complexity measures for EEG microstate sequences - concepts and algorithms\n",
      "\n",
      "üí° Content:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "**Right**: Above the critical temperature  $(3.0 \\times T_c)$  spatial features 160are apparently random (low order) but a simple independence assumption provides a good statistical 161model for the system, a situation characterized by large Kolmogorov complexity (randomness) and 162low statistical complexity.\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº‚ñº\n",
      "RESULT #3\n",
      "Relevance: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 55.0%\n",
      "\n",
      "üìÅ Source: Complexity measures for EEG microstate sequences - concepts and algorithms\n",
      "      Key: wegnerComplexityMeasuresEEG2023\n",
      "üìñ Section: $\\begin{array}{c} 362\\\\ 363 \\end{array} \\quad \\text{Lempel-Ziv complexity (LZC)} \\end{array}$\n",
      "\n",
      "üí° Content:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "429 430 431 432 433 434 435 436 With increasing temperature the entropy rate rises sigmoidally and the steepest slope occurs at the critical point. At low temperatures (T /T<sup>c</sup> = 0.2), the time courses at most lattice sites are constant, or have very few state changes.\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 7Ô∏è‚É£ Using MainProcessor (All-in-One)\n",
    "\n",
    "The `MainProcessor` class provides a convenient wrapper around all components."
   ],
   "id": "main_processor_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:54.843810Z",
     "start_time": "2025-10-22T14:40:54.779510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from legacy.MainProcessor import MainProcessor\n",
    "\n",
    "# Initialize the main processor\n",
    "processor = MainProcessor(collection_name=os.getenv('COLLECTION_NAME'))\n",
    "\n",
    "print(\"üéØ MainProcessor initialized!\\n\")\n",
    "print(\"üìã Configuration:\")\n",
    "print(f\"   üìö Collection: {os.getenv('COLLECTION_NAME')}\")\n",
    "print(f\"   üìÇ Zotero Library: {processor.zotero_library_path}\")\n",
    "print(f\"   üìù Markdown Folder: {processor.markdown_folder_path}\")\n",
    "print(f\"   üíæ Vector Index: {processor.index_path}\")\n",
    "print(f\"\\n   üìä Collection size: {processor.storage.collection.count()} documents\")"
   ],
   "id": "main_processor_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ MainProcessor initialized!\n",
      "\n",
      "üìã Configuration:\n",
      "   üìö Collection: scico-test\n",
      "   üìÇ Zotero Library: /home/soenke/Zotero\n",
      "   üìù Markdown Folder: example/markdown-library\n",
      "   üíæ Vector Index: example/zotero-vector-storage.db\n",
      "\n",
      "   üìä Collection size: 230 documents\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîÑ Query Using MainProcessor"
   ],
   "id": "processor_query_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:54.884979Z",
     "start_time": "2025-10-22T14:40:54.860445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use the processor to query\n",
    "query = \"What are the key findings?\"\n",
    "results = processor.query_vector_storage([query], n_results=3)\n",
    "\n",
    "print(f\"üîç Query: '{query}'\\n\")\n",
    "print(f\"‚úÖ Retrieved {len(results['documents'][0])} results\\n\")\n",
    "\n",
    "for i, (doc, meta) in enumerate(zip(results['documents'][0], results['metadatas'][0]), 1):\n",
    "    print(f\"Result {i}: {doc[:150]}...\")\n",
    "    print(f\"Source: {meta.get('filename')}\\n\")"
   ],
   "id": "processor_query_cell",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: 'What are the key findings?'\n",
      "\n",
      "‚úÖ Retrieved 3 results\n",
      "\n",
      "Result 1: The main results of this report can be summarized as follows:...\n",
      "Source: None\n",
      "\n",
      "Result 2: Keywords:...\n",
      "Source: None\n",
      "\n",
      "Result 3: EEG microstate research (Van de Ville et al, 2010; Jia et al, 2021), and fMRI studies(Bullmore et al, 2009; Tagliazucchi et al, 2013)....\n",
      "Source: None\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# üéì Summary & Next Steps\n",
    "\n",
    "## What We've Learned\n",
    "\n",
    "‚úÖ **Configuration**: Set up environment variables and verified Ollama  \n",
    "‚úÖ **Zotero Integration**: Connected to your library and retrieved metadata  \n",
    "‚úÖ **PDF Processing**: Converted PDFs to structured markdown  \n",
    "‚úÖ **Chunking**: Split documents into semantic pieces  \n",
    "‚úÖ **Vector Storage**: Created embeddings with ChromaDB  \n",
    "‚úÖ **Retrieval**: Performed semantic search on your knowledge base  \n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Process More Documents**: Run the pipeline on your entire collection\n",
    "2. **Fine-tune Chunking**: Adjust `chunk_size` and `overlap` for better results\n",
    "3. **Build a RAG App**: Add LLM-powered answer generation\n",
    "4. **Create a Web Interface**: Use Streamlit or Gradio for a user-friendly UI\n",
    "5. **Add Query Optimization**: Implement the `RAGQuestionOptimizer` module\n",
    "\n",
    "## üìö Helpful Functions\n",
    "\n",
    "```python\n",
    "# Search your knowledge base\n",
    "search_knowledge_base(\"your question\", n_results=5)\n",
    "\n",
    "# Get metadata for any PDF\n",
    "retriever.get_metadata_for_pdf(Path(\"path/to/file.pdf\"))\n",
    "\n",
    "# List all PDFs in a collection\n",
    "retriever.get_pdfs_in_collection(\"Collection Name\")\n",
    "\n",
    "# Query using the processor\n",
    "processor.query_vector_storage([\"query\"], n_results=5)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ù Contributing\n",
    "\n",
    "This is an evolving project! Future enhancements include:\n",
    "- Query optimization with LLMs\n",
    "- Answer generation with citations\n",
    "- Multi-document synthesis\n",
    "- Advanced RAG techniques\n",
    "\n",
    "Happy researching! üî¨üìö"
   ],
   "id": "summary_section"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# üß™ Experimental: Batch Processing\n",
    "\n",
    "Process multiple PDFs from your collection in one go."
   ],
   "id": "batch_processing_section"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:40:54.920709Z",
     "start_time": "2025-10-22T14:40:54.914985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def batch_process_collection(max_pdfs: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Process multiple PDFs from the collection.\n",
    "    WARNING: This can take a long time!\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Starting batch processing (max {max_pdfs} PDFs)...\\n\")\n",
    "    \n",
    "    pdfs = retriever.get_pdfs_in_collection(os.getenv('COLLECTION_NAME'))\n",
    "    pdfs_to_process = [p for p in pdfs if p['pdf_path']][:max_pdfs]\n",
    "    \n",
    "    total = len(pdfs_to_process)\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for i, pdf in enumerate(pdfs_to_process, 1):\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"Processing {i}/{total}: {pdf['pdf_name']}\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "        \n",
    "        try:\n",
    "            # Convert to markdown\n",
    "            print(\"üìÑ Converting to markdown...\")\n",
    "            convert_pdf_to_markdown(\n",
    "                pdf_path=pdf['pdf_path'],\n",
    "                output_path=os.getenv('MARKDOWN_FOLDER_PATH')\n",
    "            )\n",
    "            \n",
    "            # Find markdown file\n",
    "            pdf_stem = Path(pdf['pdf_path']).stem\n",
    "            md_path = Path(os.getenv('MARKDOWN_FOLDER_PATH')) / pdf_stem / f\"{pdf_stem}.md\"\n",
    "            \n",
    "            if md_path.exists():\n",
    "                # Chunk\n",
    "                print(\"‚úÇÔ∏è Chunking...\")\n",
    "                chunker = MarkdownChunker(md_path=str(md_path), chunk_size=150, chunk_overlap=50)\n",
    "                chunks = chunker.chunk()\n",
    "                \n",
    "                # Add to vector DB\n",
    "                print(f\"üì§ Adding {len(chunks)} chunks to vector DB...\")\n",
    "                storage.add_documents(chunks)\n",
    "                \n",
    "                successful += 1\n",
    "                print(f\"‚úÖ Success!\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Markdown file not found\")\n",
    "                failed += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            failed += 1\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"üìä Batch Processing Complete!\")\n",
    "    print(f\"   ‚úÖ Successful: {successful}\")\n",
    "    print(f\"   ‚ùå Failed: {failed}\")\n",
    "    print(f\"   üìö Total documents in DB: {storage.collection.count()}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "# Uncomment to run (WARNING: This will take time!)\n",
    "# batch_process_collection(max_pdfs=3)"
   ],
   "id": "batch_processing_cell",
   "outputs": [],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
